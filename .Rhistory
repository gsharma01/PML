x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
plot(x,y)
abline(lm(y~x), lwd=2)
fit<- lm(y~x)
resid(fit)
sd(resid(fit))
resid(fit)
rsd(fit)
sqrt(deviance(fit)/df.residual(fit))
mtcars
fit<-lm(weight ~ mpg )
fit<-lm(wt ~ mpg )
fit<-lm(mtcars$wt ~ mtcars$mpg )
t.test(mtcars$wt ~ mtcars$mpg)
t.test(mtcars$wt,mtcars$mpg)
t.test(mean(mtcars$wt),mtcars$mpg)
summary(fit)
coef(fit)[1]
coef(fit)[2]
summary(fit)$coefficients
summary(fit)$r
summary(fit)$r.squared
sum(summary(fit)$residuals^2)
sumCoef <- summary(fit)$coefficients
sumCoef[1,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[1, 2]
sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]
plot(mtcars$wt,mtcars$mpg )
abline(lm(weight ~ mpg ), data =mtcars)
abline(lm(weight ~ mpg , data =mtcars), lwd=2)
abline(lm(wt ~ mpg , data =mtcars), lwd=2)
plot(abline(lm(wt ~ mpg , data =mtcars), lwd=2))
abline(lm(wt ~ mpg , data =mtcars), lwd=2)
plot(mtcars$wt,mtcars$mpg )
abline(lm(wt ~ mpg , data =mtcars), lwd=2)
head(mtcars$wt)
head(wt)
mtcars$wt
mtcars
sumCoef <- summary(fit)$coefficients
sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]
(sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2])[1] - (sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2])[2]
(sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2])[1] + (sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2])[2]
confint(fit)
confint(fit,"wt")
fit1<-lm(mtcars$mpg ~ mtcars$wt )
confint(fit1)
confint(fit1, level=0.95)
confint(fit1)
confint(fit)
confint(fit, level=0.95)
confint(fit1,"mpg")
confint(fit1,"wt")
confint(fit1,mtcars$wt)
x<- mtcars$wt
y<- mtcars$mpg
plot(x, y,frame=FALSE,xlab="Carat",ylab="Dollars",pch=21,col="black", bg="lightblue", cex=2)
abline(fit, lwd = 2)
xVals <- seq(min(x), max(x), by = .01)
yVals <- beta0 + beta1 * xVals
se1 <- sigma * sqrt(1 / n + (xVals - mean(x))^2/ssx)
se2 <- sigma * sqrt(1 + 1 / n + (xVals - mean(x))^2/ssx)
lines(xVals, yVals + 2 * se1)
lines(xVals, yVals - 2 * se1)
lines(xVals, yVals + 2 * se2)
lines(xVals, yVals - 2 * se2)
n <- length(y)
beta1 <- cor(y, x) * sd(y) / sd(x)
beta0 <- mean(y) - beta1 * mean(x)
e <- y - beta0 - beta1 * x
sigma <- sqrt(sum(e^2) / (n-2))
ssx <- sum((x - mean(x))^2)
seBeta0 <- (1 / n + mean(x) ^ 2 / ssx) ^ .5 * sigma
seBeta1 <- sigma / sqrt(ssx)
tBeta0 <- beta0 / seBeta0; tBeta1 <- beta1 / seBeta1
pBeta0 <- 2 * pt(abs(tBeta0), df = n - 2, lower.tail = FALSE)
pBeta1 <- 2 * pt(abs(tBeta1), df = n - 2, lower.tail = FALSE)
coefTable <- rbind(c(beta0, seBeta0, tBeta0, pBeta0), c(beta1, seBeta1, tBeta1, pBeta1))
colnames(coefTable) <- c("Estimate", "Std. Error", "t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)", "x")
plot(x, y,frame=FALSE,xlab="Carat",ylab="Dollars",pch=21,col="black", bg="lightblue", cex=2)
abline(fit, lwd = 2)
xVals <- seq(min(x), max(x), by = 3)
yVals <- beta0 + beta1 * xVals
se1 <- sigma * sqrt(1 / n + (xVals - mean(x))^2/ssx)
se2 <- sigma * sqrt(1 + 1 / n + (xVals - mean(x))^2/ssx)
lines(xVals, yVals + 2 * se1)
lines(xVals, yVals - 2 * se1)
lines(xVals, yVals + 2 * se2)
lines(xVals, yVals - 2 * se2)
x
y
fit <- lm(y ~ x);
xVals
seq(min(x), max(x), by = 3)
beta0
beta1
beta0 + beta1 * xVals
lm(xVals~ yVals)
lm(yVals ~ xVals)
fit<-lm(yVals ~ xVals)
cofint(fit)
confint(fit)
summary(fit)
fit<- lm(y ~ x)
fit
newData <- data.frame(x=3)
predict(fit, newData, interval="confidence")
y
mtcars
newData <- data.frame(x=2)
predict(fit, newData, interval="confidence")
newData <- data.frame(x=2, y=1)
predict(fit, newData, interval="confidence")
newData <- data.frame(y=1)
predict(fit, newData, interval="confidence")
fit<- lm(x ~ y)
fit
newData <- data.frame(x=1)
predict(fit, newData, interval="confidence")
newData <- data.frame(y=2)
predict(fit, newData, interval="confidence")
fit
plot(fit, lwd=2)
plot(x,y, lwd=2)
summary(fit)
cofint(fit)
confint(fit)
fit<- lm(y ~ x)
plot(x,y, lwd=2)
confint(fit)
fit<- lm(x ~ y)
confint(fit)
newData <- data.frame(x=1)
predict(fit, newData, interval="confidence")
newData <- data.frame(x=1, y=2)
predict(fit, newData, interval="confidence")
ssx <- sum((x - mean(x))^2)
sd(x)^2
sd(x)^2/ ssx
n <- length(y)
beta1 <- cor(y, x) * sd(y) / sd(x)
beta0 <- mean(y) - beta1 * mean(x)
e <- y - beta0 - beta1 * x
sigma <- sqrt(sum(e^2) / (n-2))
ssx <- sum((x - mean(x))^2)
seBeta0 <- (1 / n + mean(x) ^ 2 / ssx) ^ .5 * sigma
seBeta1 <- sigma / sqrt(ssx)
tBeta0 <- beta0 / seBeta0; tBeta1 <- beta1 / seBeta1
pBeta0 <- 2 * pt(abs(tBeta0), df = n - 2, lower.tail = FALSE)
pBeta1 <- 2 * pt(abs(tBeta1), df = n - 2, lower.tail = FALSE)
coefTable <- rbind(c(beta0, seBeta0, tBeta0, pBeta0), c(beta1, seBeta1, tBeta1, pBeta1))
colnames(coefTable) <- c("Estimate", "Std. Error", "t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)", "x")
coefTable
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ncol(training)
training
head(training)
preProc<- preProcess(log10(training)+1), method="pca",pcaComp=2)
preProc<- preProcess(log10(training+1)), method="pca",pcaComp=2)
preProc<- preProcess(log10(training)), method="pca",pcaComp=2)
preProc<- preProcess(log10(training+1), method="pca",pcaComp=2)
head(training)
head(training[,1])
head(training[,58])
training[,58]
preProc<- preProcess(log10(training[,58]+1), method="pca",pcaComp=2)
preProc<- preProcess(training[,58], method="pca",pcaComp=2)
length(training[,58])
abs(cor(training[,58]))
library(kernlab)
data(spam)
spam
head(spam)
head(spam[,58])
spam[,58]
spam
ncol(spam)
ncol(training)
ncol(training[,131])
training[,131]
preProc<- preProcess(log10(training[,131]+1), method="pca",pcaComp=2)
preProc<- preProcess(training[,131], method="pca",pcaComp=2)
preProc<- preProcess(data.frame(training[,131]), method="pca",pcaComp=2)
preProc<- preProcess(data.frame(log10(training[,131]+1), method="pca",pcaComp=2)
)
preProc<- preProcess(data.frame(log10(training[,131]+1)), method="pca",pcaComp=2)
preProc<- preProcess(data.frame(training[,131]+1), method="pca",pcaComp=2)
library(sqldf)
sqldf("alter table training add value number")
training
ncol(training)
sqldf("select distinct genotype from training")
sqldf("Select case Genotype when 'E2E2' then 1 when 'E2E3' then 2 when 'E2E4' then 3 when 'E3E3' then 4 when 'E3E4' then 5 when 'E3E4' then 6 when 'E4E4' then 7 end from training")
sqldf("Select (case Genotype when 'E2E2' then 1 when 'E2E3' then 2 when 'E2E4' then 3 when 'E3E3' then 4 when 'E3E4' then 5 when 'E3E4' then 6 when 'E4E4' then 7 end) as Genetype from training")
Analysis<-sqldf("Select (case Genotype when 'E2E2' then 1 when 'E2E3' then 2 when 'E2E4' then 3 when 'E3E3' then 4 when 'E3E4' then 5 when 'E3E4' then 6 when 'E4E4' then 7 end) as Genetype from training")
preProc<- preProcess(data.frame(log10(Analysis+1)), method="pca",pcaComp=2)
preProc<- preProcess(data.frame(log10(Analysis)), method="pca",pcaComp=2)
preProc<- preProcess(data.frame(Analysis), method="pca",pcaComp=2)
preProc<- preProcess(data.frame(Analysis), method="pca")
head(training)
?preprocess()
?preProcess()
colNames(training)
colnames(training)
sqldf("Select IL_13, IL_17E, IL_3, IL_5,IL_6_Receptor, IL_8, IL_11, IL_16,IL_1alpha,IL_4, IL_6,IL_7 from training ")
Analysis<-sqldf("Select IL_13, IL_17E, IL_3, IL_5,IL_6_Receptor, IL_8, IL_11, IL_16,IL_1alpha,IL_4, IL_6,IL_7 from training ")
Analysis
preProc<- preProcess(log10(Analysis+1), method="pca",pcaComp=2)
preProc<- preProcess(Analysis, method="pca")
trainPC<- predict(preProc,Analysis )
modelFit<- train(training$Genotype ~ .,method="glm", data=trainPC )
modelFit<- train(training$Genotype,method="glm", data=trainPC )
?train
modelFit<- train(training,method="glm", data=trainPC )
modelFit<- train(training$Genotype ~ .,training$Genotype,method="glm", data=trainPC )
modelFit<- train(training$Genotype ~ .,Analysis,method="glm", data=trainPC )
modelFit<- train(training$Genotype ~ .,method="glm", data=trainPC )
ncol(Analysis)
summary(fit)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit<- lm(y~x)
summary(fit)
x<- mtcars$wt
y<-mtcars$mpg
fit<- lm(y~x)
summary(fit)
?confint
confint(fit)
fit<- lm(y~mean(x))
fit<- lm(y ~ x)
newData <- data.frame(x=3)
predict(fit, newData, interval="confidence")
fit<- lm(y ~ x)
newData <- data.frame(x=4)
predict(fit, newData, interval="confidence")
fit<- lm(x ~ y)
newData <- data.frame(y=3)
predict(fit, newData, interval="confidence")
fit<- lm(y ~ x)
newData <- data.frame(x=3,y=1)
predict(fit, newData, interval="confidence")
fit<- lm(x ~ y)
newData <- data.frame(x=1,y=3)
predict(fit, newData, interval="confidence")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
training$Superplasticizer
log(training$Superplasticizer+1)
hist(log(training$Superplasticizer+1))
setwd("C:\\Users\\GauravGeet\\coursera\\PML")
library(caret, randomForest)
# load data
trainRawData <- read.csv("pml-training.csv",na.strings=c("NA",""))
# discard NAs
NAs <- apply(trainRawData,2,function(x) {sum(is.na(x))})
validData <- trainRawData[,which(NAs == 0)]
# make training set
trainIndex <- createDataPartition(y = validData$classe, p=0.2,list=FALSE) # 3927 rows
trainData <- validData[trainIndex,]
# discards unuseful predictors
removeIndex <- grep("timestamp|X|user_name|new_window",names(trainData))
trainData <- trainData[,-removeIndex]
training<-trainData
#Cross Validation and Out of Sample Error
k=10
foldSize <- floor(nrow(training)/k)
errVect<- rep(NA,k)
modFit <- train(classe ~.,data = training,method="rf")
modFit
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
testing<- read.csv("pml-testing.csv")
modPredict<- predict(modFit,testing)
modPredict
pml_write_files(modPredict)
trainRawData <- read.csv("pml-training.csv",na.strings=c("NA",""))
NAs <- apply(trainRawData,2,function(x) {sum(is.na(x))})
validData <- trainRawData[,which(NAs == 0)]
trainData <- trainData[,-removeIndex]
training<-trainData
knit2html
library(knitr)
knit2html
?knit2html
knit2html("PracticleMLProject.RMD")
k=3
foldSize <- floor(nrow(training)/k)
errVect<- rep(NA,k)
for (i in 1:k)
{
set1<- ((i-1)*foldSize+1)
set2<- (i*foldSize)
subSet <- set1:set2
cvTrain = training[-subSet,]
cvTest = training[subSet,]
cvModFit <- train(cvTrain[,-1], y = as.factor(cvTrain[,1]) ,data = cvTrain,method="rf")
cvPredict<- predict(cvModFit,newData = cvTest[,1],type="prob")[,2]
errVect[i]<- roc.area(cvTest[,1],cvPredict)$A
print(paste("Area under ROC for fold", i, ":", errVect[i]))
}
print(paste("Average Area Under ROC:", mean(errVect))
k=3
foldSize <- floor(nrow(training)/k)
errVect<- rep(NA,k)
for (i in 1:k)
{
set1<- ((i-1)*foldSize+1)
set2<- (i*foldSize)
subSet <- set1:set2
cvTrain = training[-subSet,]
cvTest = training[subSet,]
cvModFit <- randomForest(cvTrain[,-1], y = as.factor(cvTrain[,1]) ,data = cvTrain,method="rf")
cvPredict<- predict(cvModFit,newData = cvTest[,1],type="prob")[,2]
errVect[i]<- roc.area(cvTest[,1],cvPredict)$A
print(paste("Area under ROC for fold", i, ":", errVect[i]))
}
print(paste("Average Area Under ROC:", mean(errVect))
install.packages("verification")
library("verification")
k=10
foldSize <- floor(nrow(training)/k)
errVect<- rep(NA,k)
for (i in 1:k)
{
set1<- ((i-1)*foldSize+1)
set2<- (i*foldSize)
subSet <- set1:set2
cvTrain = training[-subSet,]
cvTest = training[subSet,]
cvModFit <- randomForest(cvTrain[,-1], y = as.factor(cvTrain[,1]) ,data = cvTrain,method="rf")
cvPredict<- predict(cvModFit,newData = cvTest[,1],type="prob")[,2]
errVect[i]<- roc.area(cvTest[,1],cvPredict)$A
print(paste("Area under ROC for fold", i, ":", errVect[i]))
}
print(paste("Average Area Under ROC:", mean(errVect))
k=10
foldSize <- floor(nrow(training)/k)
errVect<- rep(NA,k)
for (i in 1:k)
{
set1<- ((i-1)*foldSize+1)
set2<- (i*foldSize)
subSet <- set1:set2
cvTrain = training[-subSet,]
cvTest = training[subSet,]
cvModFit <- randomForest(cvTrain[,-1], y = as.factor(cvTrain[,1])) #Random forest on Train
cvPredict<- predict(cvModFit,newData = cvTest[,1],type="prob")[,2]
errVect[i]<- roc.area(cvTest[,1],cvPredict)$A #Area under ROC Vector
print(paste("Area under ROC for fold", i, ":", errVect[i])) #Printing each out of sample error
}
print(paste("Average Area Under ROC:", mean(errVect)) #Mean of sample errors
nrow(training)
floor(nrow(training)/k)
floor(nrow(training)/9)
nrow(training)/9
nrow(training)/3
#Cross Validation and Out of Sample Error
k=3
foldSize <- floor(nrow(training)/k)
errVect<- rep(NA,k)
for (i in 1:k)
{
set1<- ((i-1)*foldSize+1)
set2<- (i*foldSize)
subSet <- set1:set2
cvTrain = training[-subSet,]
cvTest = training[subSet,]
cvModFit <- randomForest(cvTrain[,-1], y = as.factor(cvTrain[,1])) #Random forest on Train
cvPredict<- predict(cvModFit,newData = cvTest[,1],type="prob")[,2]
errVect[i]<- roc.area(cvTest[,1],cvPredict)$A #Area under ROC Vector
print(paste("Area under ROC for fold", i, ":", errVect[i])) #Printing each out of sample error
}
print(paste("Average Area Under ROC:", mean(errVect)) #Mean of sample errors
for (i in 1:k)
{
set1<- ((i-1)*foldSize+1)
set2<- (i*foldSize)
subSet <- set1:set2
cvTrain = training[-subSet,]
cvTest = training[subSet,]
cvModFit <- train(classe ~.,data=cvTrain, method="rf") #Random forest on Train
cvPredict<- predict(cvModFit,newData = cvTest[,1],type="prob")[,2]
errVect[i]<- roc.area(cvTest[,1],cvPredict)$A #Area under ROC Vector
print(paste("Area under ROC for fold", i, ":", errVect[i])) #Printing each out of sample error
}
i=1
set1<- ((i-1)*foldSize+1)
set2<- (i*foldSize)
subSet <- set1:set2
cvTrain = training[-subSet,]
cvTest = training[subSet,]
cvModFit <- train(classe ~.,data=cvTrain, method="rf") #Random forest on Train
head(cvTrain)
cvModFit <- train(classe ~.,data = cvTrain,method="rf")
?train
cvModFit <- train(classe ~., y= cvTrain[,-1],data = cvTrain,method="rf")
cvModFit <- train(classe ~., y= as.factor(cvTrain[,1]),data = cvTrain,method="rf")
cvModFit <- train(classe ~., y= as.factor(cvTrain[,1]),data = cvTrain)
randomForest(x=cvTrain[,-1], y= as.factor(cvTrain[,1]))
k=3
foldSize <- floor(nrow(training)/k)
errVect<- rep(NA,k)
for (i in 1:k)
{
set1<- ((i-1)*foldSize+1)
set2<- (i*foldSize)
subSet <- set1:set2
cvTrain = training[-subSet,]
cvTest = training[subSet,]
cvModFit <- randomForest(x=cvTrain[,-1], y = as.factor(cvTrain[,1]))
cvPredict<- predict(cvModFit,newData = cvTest[,1],type="prob")[,2]
errVect[i]<- roc.area(cvTest[,1],cvPredict)$A
print(paste("Area under ROC for fold", i, ":", errVect[i]))
}
print(paste("Average Area Under ROC:", mean(errVect))
k=1
foldSize <- floor(nrow(training)/k)
errVect<- rep(NA,k)
for (i in 1:k)
{
set1<- ((i-1)*foldSize+1)
set2<- (i*foldSize)
subSet <- set1:set2
cvTrain = training[-subSet,]
cvTest = training[subSet,]
cvModFit <- randomForest(x=cvTrain[,-1], y = as.factor(cvTrain[,1]))
cvPredict<- predict(cvModFit,newData = cvTest[,1],type="prob")[,2]
errVect[i]<- roc.area(cvTest[,1],cvPredict)$A
print(paste("Area under ROC for fold", i, ":", errVect[i]))
}
print(paste("Average Area Under ROC:", mean(errVect))
i
i<-1
set1<- ((i-1)*foldSize+1)
set2<- (i*foldSize)
subSet <- set1:set2
cvTrain = training[-subSet,]
cvTest = training[subSet,]
cvModFit <- randomForest(x=cvTrain[,-1], y = as.factor(cvTrain[,1]))
1=1
i=1
i
set1<- ((i-1)*foldSize+1)
set2<- (i*foldSize)
subSet <- set1:set2
cvTrain = training[-subSet,]
cvTest = training[subSet,]
cvTrain
k=3
foldSize <- floor(nrow(training)/k)
errVect<- rep(NA,k)
set1<- ((i-1)*foldSize+1)
set2<- (i*foldSize)
subSet <- set1:set2
cvTrain = training[-subSet,]
cvTest = training[subSet,]
cvTrain
cvModFit <- randomForest(x=cvTrain[,-1], y = as.factor(cvTrain[,1]))
cvModFit
cvPredict<- predict(cvModFit,newData = cvTest[,1],type="prob")[,2]
cvPredict
errVect[i]<- roc.area(cvTest[,1],cvPredict)$A
?Roc.area
?roc.area
cvTest
cvTest[,1]
cvTraning[,1]
cvTrain
errVect[i]<- roc.area(cvTest[,1],cvPredict)$A
errVect[i]<- roc.area(cvTest,cvPredict)$A
wilcox.test(cvTest[,1],cvPredict)
install.packages("ROCR")
library(ROCR)
install.packages("AUC")
library(AUC)
?ROC
?roc
roc(cvTest[,1],cvPredict)
head(cvTest[,1])
cvTest[,1]
roc(training[,1],cvPredict)
